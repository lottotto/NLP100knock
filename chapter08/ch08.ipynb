{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: 機械学習\n",
    "本章では，Bo Pang氏とLillian Lee氏が公開しているMovie Review Dataのsentence polarity dataset v1.0を用い，文を肯定的（ポジティブ）もしくは否定的（ネガティブ）に分類するタスク（極性分析）に取り組む．\n",
    "### 70. データの入手・整形\n",
    "文に関する極性分析の正解データを用い、以下の要領で正解データ(sentiment.txt)を作成せよ。\n",
    "1. rt-polarity.posの各行の先頭に\"+1 \"という文字列を追加する（極性ラベル\"+1\"とスペースに続けて肯定的な文の内容が続く）\n",
    "2. rt-polarity.negの各行の先頭に\"-1 \"という文字列を追加する（極性ラベル\"-1\"とスペースに続けて否定的な文の内容が続く）\n",
    "3. 上述1と2の内容を結合（concatenate）し，行をランダムに並び替える\n",
    "\n",
    "sentiment.txtを作成したら，正例（肯定的な文）の数と負例（否定的な文）の数を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5331 5331\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "pos_sent = open('./resource/rt-polaritydata/rt-polarity.pos','r',encoding='cp1252')\n",
    "neg_sent = open('./resource/rt-polaritydata/rt-polarity.neg','r',encoding='cp1252')\n",
    "temp_pos_sentList = []\n",
    "temp_neg_sentList = []\n",
    "for pos in pos_sent:\n",
    "    temp_pos_sentList.append(\"+1 \"+pos)\n",
    "for neg in neg_sent:\n",
    "    temp_neg_sentList.append(\"-1 \"+neg)\n",
    "    \n",
    "sentList = temp_pos_sentList + temp_neg_sentList\n",
    "random.shuffle(sentList)\n",
    "\n",
    "with open('./resource/sentiment.txt','w') as ret_file:\n",
    "    ret_file.writelines(sentList)\n",
    "    \n",
    "    \n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "with open('./resource/sentiment.txt','r') as check_file:\n",
    "    for line in check_file:\n",
    "        if line[0:2] == \"+1\":\n",
    "            pos_count += 1\n",
    "        else:\n",
    "            neg_count += 1\n",
    "print(pos_count, neg_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 71. ストップワード\n",
    "英語のストップワードのリスト(ストップリスト)を適当に作成せよ。さらに、引数に与えられた単語(文字列)がストップワードに含まれている場合は真、それ以外は偽を返す関数を実装せよ。さらに、その関数に対するテストを記述せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109c75828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "file = open('./resource/sentiment.txt','r')\n",
    "sentList = file.readlines()\n",
    "sentList = \" \".join(sentList).split()\n",
    "WordTimesAppear = Counter(sentList).most_common()\n",
    "Word_Df = pd.DataFrame(WordTimesAppear)\n",
    "Word_Df.columns = [\"word\", \"times\"]\n",
    "Word_Df['times'].cumsum().plot()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#150000あたりまでは切っていい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150220"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word_Df['times'].cumsum()[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.', 'the', ',', 'a', 'and', 'of', '-1', '+1', 'to', 'is', 'in', 'that', 'it', 'as', 'but', 'with', 'film', 'this', 'for', 'its', 'an', 'movie', \"it's\", 'be', 'on', 'you', 'not', 'by', 'about', 'more', 'one', 'like', 'has', 'are', 'at', 'from', 'than', '\"', 'all', '--', 'his', 'have', 'so', 'if', 'or', 'story', 'i', 'too', 'just', 'who', 'into', 'what', 'most', 'out', 'no', 'much', 'even', 'good', 'up', 'will', 'comedy', 'time', 'can', 'some', 'characters', 'only', 'little', 'way', 'their', 'funny', 'make', 'enough', 'been', 'very', 'your', 'never', 'when', 'makes', 'there', 'may', 'which', 'us', 'work', 'best', 'he', 'bad', 'director', \"doesn't\", ')', '?', 'any', '(', 'love', 'would', 'life', 'while', 'they', 'we', ':', 'was', \"there's\", 'movies', 'new', 'well', 'her', 'through', 'could', 'really', 'something', 'how', 'made', 'them', 'does', 'performances', 'own', 'should', 'many', 'drama', \"that's\", 'those', 'plot', 'look', 'films', \"isn't\", 'every', 'see', 'still', 'two', 'nothing', 'people', 'better', 'long', 'without', 'other', 'get', 'off', 'fun', 'being', 'action', 'both', 'great', 'though', 'might', 'big', \"'\", 'also', 'cast', 'another', 'do', 'kind', 'humor', 'first', 'audience', 'between', 'sense', 'such', 'over', 'character', 'ever', \"don't\", ';', 'performance', 'feels', 'few', 'because', 'script', \"film's\", 'here', 'far', 'often', 'seems', 'less', 'thing', 'minutes', 'real', 'feel', 'world', 'picture', 'tale', 'almost', 'thriller', \"can't\", 'down', 'quite', 'documentary', 'interesting', 'yet', '!', 'these', 'entertaining', 'rather', \"you're\", 'screen', 'my', 'end', 'itself', 'seen', 'full', 'watching', 'take', 'hollywood', 'ultimately', 'go', 'hard', 'heart', 'moments', 'de', 'comes', 'romantic', 'despite', 'lot', 'american', 'were', 'me', 'after', 'where', 'before', 'family', 'acting', 'original', 'had', 'old', 'then', 'find', 'right', 'gets', 'worth', 'human', 'same', 'takes', 'come', 'things', 'times', 'dialogue', 'back', 'watch', 'man', 'actors', 'scenes', 'our', 'material', 'compelling', 'young', 'once', 'music', 'years', 'works', 'think', 'seem', 'anyone', 'emotional', 'gives', 'want', 'going', 'know', 'least', 'part', 'say', 'sometimes', 'piece', 'again', 'cinematic', 'entertainment', 'point', \"you'll\", 'give', 'kids', 'pretty', 'subject', 'last', 'keep', 'bit', 'making', 'special', 'together', 'why', 'fascinating', 'cinema', 'dull', 'whole', 'anything', 'fans', 'year', '-', 'moving', 'away', 'since', 'manages', 'need', 'style', 'star', 'laughs', 'show', 'true', 'clever', 'history', 'always', 'experience', 'sweet', 'offers', 'simply', 'high', 'mr', 'direction', 'silly', 'dark', 'instead', 'predictable', 'charm', 'him', 'whose', 'care', 'actually')\n"
     ]
    }
   ],
   "source": [
    "StopWordList = list(zip(*Counter(sentList).most_common()[:313]))[0]\n",
    "print(StopWordList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引数に与えられた単語（文字列）がストップリストに含まれている場合は真  \n",
    "それ以外は偽を返す関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isStopWord(word):\n",
    "    if word in StopWordList:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['simply', 72],\n",
       "       ['high', 72],\n",
       "       ['mr', 72],\n",
       "       ['direction', 72],\n",
       "       ['silly', 71],\n",
       "       ['dark', 71],\n",
       "       ['instead', 71],\n",
       "       ['predictable', 70],\n",
       "       ['charm', 70],\n",
       "       ['him', 70],\n",
       "       ['whose', 70],\n",
       "       ['care', 70],\n",
       "       ['actually', 70]], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(Word_Df[Word_Df['word'].apply(isStopWord)][300:320])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 72. 素性抽出\n",
    "極性分析に有用そうな素性を各自で設計し、学習データから素性を抽出せよ。素性としては、レビューからストップワードを除去し、各単語をステミング処理したものが最低限のベースになるであろう。  \n",
    "skilearnのモジュール  \n",
    "CountVectorizer:\n",
    "param\n",
    "- Input filename or file or content\n",
    "- tokenizer callable object, 関数を渡して、処理する？？\n",
    "- stop_words\n",
    "- ngram_range これを増やすと、n_gram単位でベクトル化してくれる  \n",
    "使用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>appropri</th>\n",
       "      <th>belong</th>\n",
       "      <th>chateau</th>\n",
       "      <th>clariti</th>\n",
       "      <th>conclud</th>\n",
       "      <th>crisp</th>\n",
       "      <th>dawn</th>\n",
       "      <th>entir</th>\n",
       "      <th>...</th>\n",
       "      <th>nonstop</th>\n",
       "      <th>pace</th>\n",
       "      <th>portrait</th>\n",
       "      <th>rudd</th>\n",
       "      <th>spout</th>\n",
       "      <th>strength</th>\n",
       "      <th>summer</th>\n",
       "      <th>therapy-depend</th>\n",
       "      <th>unfold</th>\n",
       "      <th>unhurri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  afternoon  appropri  belong  chateau  clariti  conclud  crisp  \\\n",
       "0       1          1         1       0        0        1        1      1   \n",
       "1       0          0         0       1        1        0        0      0   \n",
       "\n",
       "   dawn  entir   ...     nonstop  pace  portrait  rudd  spout  strength  \\\n",
       "0     1      1   ...           0     1         0     0      0         1   \n",
       "1     0      0   ...           1     0         1     1      1         0   \n",
       "\n",
       "   summer  therapy-depend  unfold  unhurri  \n",
       "0       1               0       1        1  \n",
       "1       0               1       0        0  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "Stemmer = PorterStemmer()\n",
    "\n",
    "#文を渡してsteming処理を行う関数\n",
    "def token_processing(text):\n",
    "    return [Stemmer.stem(token) for token in text.split()]\n",
    "                 \n",
    "    \n",
    "judge_texts = [\"the film's unhurried pace is actually one of its strengths . entirely appropriately , the tale unfolds like a lazy summer afternoon and concludes with the crisp clarity of a fall dawn . \",\n",
    "       \"the chateau belongs to rudd , whose portrait of a therapy-dependent flakeball spouting french malapropisms . . . is a nonstop hoot . \"]\n",
    "\n",
    "CV = CountVectorizer(tokenizer=token_processing, stop_words=StopWordList)\n",
    "temp_X = CV.fit_transform(judge_texts)\n",
    "Df = pd.DataFrame(temp_X.toarray())\n",
    "Df.columns = CV.get_feature_names()\n",
    "Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "file = open('./sentiment.txt','r')\n",
    "temp = file.readlines()\n",
    "texts = list(map(lambda x:x[2:], temp))\n",
    "labels = np.array(list(map(lambda x:int(x[0:2]), temp)))\n",
    "CV = CountVectorizer(tokenizer=token_processing, stop_words=StopWordList)\n",
    "LR = LogisticRegression()\n",
    "Vectorized_text = CV.fit_transform(texts).toarray()\n",
    "clf = LR.fit(Vectorized_text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clf.score(Vectorized_text, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 74. 予測\n",
    "73で学習したロジスティック回帰モデルを用い、与えられた文の極性ラベル(正例なら\"+1\", 負例なら\"-1\")とその予測確率を計算するプログラムを実装せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(Vectorized_text)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75.  素性の重み\n",
    "73で学習したロジスティック回帰モデルの中で，重みの高い素性トップ10と，重みの低い素性トップ10を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"GOOD WORD\\n\")\n",
    "for i in np.argsort(clf.coef_[0])[::-1][:10]:\n",
    "    print(\"Word: {}\\t\\t Weight:{}\".format(CV.get_feature_names()[i], clf.coef_[0][i]))\n",
    "    \n",
    "print(\"\\nBAD WORD\\n\")\n",
    "for i in np.argsort(clf.coef_[0])[:10]:\n",
    "    print(\"Word: {}\\t\\t Weight:{}\".format(CV.get_feature_names()[i], clf.coef_[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 76. ラベル付け\n",
    "学習データに対し、ロジスティック回帰モデルを適用し、正解のラベル、予測されたラベル、予測確率をタブ区切り形式で出力せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Vectorized_text.shape)\n",
    "print(Vectorized_text[0].reshape(1,-1).shape)\n",
    "clf.predict_proba(Vectorized_text[0].reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./resource/sentiment.txt', 'r').readlines()\n",
    "Ans76List = []\n",
    "for text, Vectorize in zip(file, Vectorized_text):\n",
    "    Correct_Label = int(text[0:2])\n",
    "    Predict_Label = clf.predict(Vectorize.reshape(1,-1))[0]\n",
    "    Predict_Prob = max(clf.predict_proba(Vectorize.reshape(1,-1))[0])\n",
    "    Ans76List.append([Correct_Label, Predict_Label])\n",
    "    print(\"Correct_Label:{}, Predict_Label:{}, Predict_Prob:{:.2f}\".format(Correct_Label, Predict_Label, Predict_Prob))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 77. 正解率の計測\n",
    "76の出力を受け取り、予測の正解率、正例に関する適合率、再現率、F1スコアを求めるプログラムを作成せよ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#正例に関する適合率\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "for i in Ans76List:\n",
    "    if i[0] == 1:\n",
    "        if i[1]==1:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "    else:\n",
    "        if i[1] == 1:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "            \n",
    "Correct = (TP+TN)/len(Ans76List)\n",
    "Precision = TP/(TP+FP)\n",
    "Recall = TP/(TP+FN)\n",
    "print(\"正解率:\",Correct)\n",
    "print(\"正例適合率:\", Precision)\n",
    "print(\"再現率:\", Recall)\n",
    "print(\"F1スコア:\", 2*Precision*Recall/(Recall+Precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}, {}\\n{}, {}\".format(TN, FP, FN, TP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(labels, clf.predict(Vectorized_text))\n",
    "print(conf_matrix)\n",
    "count = sum(sum(conf_matrix))\n",
    "print(\"正解率:\", (conf_matrix[0][0]+conf_matrix[1][1])/count)\n",
    "print(\"正例適合率:\", conf_matrix[0][0]/(conf_matrix[0][0]+conf_matrix[0][1]))\n",
    "print(\"再現率:\", conf_matrix[1][1]/ (conf_matrix[1][1]+conf_matrix[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|||\n",
    "|-|-|\n",
    "|5080|251|\n",
    "|316|5015|\n",
    "5080が真陽性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "predict_labels = clf.predict(Vectorized_text)\n",
    "print(clf.score(Vectorized_text, labels))\n",
    "print(precision_score(labels, predict_labels))\n",
    "print(recall_score(labels, predict_labels))\n",
    "print(f1_score(labels, predict_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 78. 5分割交差検定\n",
    "76-77の実験では，学習に用いた事例を評価にも用いたため，正当な評価とは言えない．すなわち，分類器が訓練事例を丸暗記する際の性能を評価しており，モデルの汎化性能を測定していない．そこで，5分割交差検定により，極性分類の正解率，適合率，再現率，F1スコアを求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "print(\"precision\\trecall\\tf1\")\n",
    "skfolds = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skfolds.split(Vectorized_text, labels):\n",
    "    temp_clf = LogisticRegression()\n",
    "    Train_Vectorized_text_fold = Vectorized_text[train_index]\n",
    "    Train_Label_fold = labels[train_index]\n",
    "    Test_Vectorized_text_fold = Vectorized_text[test_index]\n",
    "    Test_Label_fold = labels[test_index]\n",
    "    \n",
    "    temp_clf.fit(Train_Vectorized_text_fold, Train_Label_fold)\n",
    "    label_predict = temp_clf.predict(Test_Vectorized_text_fold)\n",
    "    \n",
    "    precision = precision_score(Test_Label_fold, label_predict)\n",
    "    recall = recall_score(Test_Label_fold, label_predict)\n",
    "    f1 = f1_score(Test_Label_fold, label_predict)\n",
    "    \n",
    "    print(\"{:.2f}\\t\\t{:.2f}\\t{:.2f}\".format(precision, recall, f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 79. 適合率-再現率グラフの描画\n",
    "ロジスティック回帰モデルの分類の閾値を変化させることで、適合率-再現率を描画せよ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_prob = clf.predict_proba(Vectorized_text)\n",
    "# print(y_prob[:,1:2])\n",
    "# print(labels[0:3])\n",
    "p, r, t = precision_recall_curve(labels, y_prob[:, 1:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"precision\": p, \"recall\": r}) \n",
    "df.plot(x=\"precision\",y=\"recall\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
